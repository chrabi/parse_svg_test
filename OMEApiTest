import requests
import csv
import concurrent.futures
import sys
import os
import logging
from datetime import datetime, timezone

# Konfiguracja logowania
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("script.log"),
        logging.StreamHandler()
    ]
)

# Konfiguracja
BASE_URL = "https://{ip}/api/DeviceService"  # Podstawowy URL do API OME
DEVICES_ENDPOINT = "/Devices"  # Endpoint do pobierania listy urządzeń
HEADERS = {
    "Content-Type": "application/json",
    "X-Auth-Token": "your_auth_token_here"  # Zastąp tokenem uwierzytelniającym
}

OUTPUT_DIR = "out_files"  # Główny katalog wynikowy

def parse_date_to_epoch(date_str):
    """
    Konwertuje różne formaty daty do czasu UTC, a następnie do formatu epoch.
    Obsługuje formaty ISO, Windows i inne.
    """
    if not date_str:
        return None

    # Próbuj różne formaty daty
    formats = [
        "%Y-%m-%dT%H:%M:%S.%fZ",  # ISO format z czasem UTC (np. 2023-10-10T12:34:56.789Z)
        "%Y-%m-%dT%H:%M:%S.%f%z", # ISO format z informacją o strefie czasowej (np. 2023-10-10T12:34:56.789+02:00)
        "%Y-%m-%d %H:%M:%S",      # Windows format (bez strefy czasowej)
        "%Y/%m/%d %H:%M:%S",      # Inny format (bez strefy czasowej)
    ]

    for fmt in formats:
        try:
            dt = datetime.strptime(date_str, fmt)
            # Jeśli data ma informację o strefie czasowej, przekonwertuj do UTC
            if dt.tzinfo is not None:
                dt = dt.astimezone(timezone.utc)
            else:
                # Załóż, że data jest już w UTC
                dt = dt.replace(tzinfo=timezone.utc)
            return int(dt.timestamp())  # Konwertuj do epoch
        except ValueError:
            continue

    logging.warning(f"Nie można sparsować daty: {date_str}")
    return None

def fetch_all_devices(ip):
    """
    Pobiera wszystkie urządzenia z paginacją (@odata.nextLink).
    """
    url = BASE_URL.format(ip=ip) + DEVICES_ENDPOINT
    all_devices = []

    while url:
        try:
            response = requests.get(url, headers=HEADERS, verify=False)  # verify=False wyłącza weryfikację SSL
            response.raise_for_status()
            data = response.json()
            all_devices.extend(data.get("value", []))
            url = data.get("@odata.nextLink")  # Pobierz kolejną stronę danych
        except requests.exceptions.RequestException as e:
            logging.error(f"Błąd podczas pobierania listy urządzeń z {url}: {e}")
            break

    return all_devices

def fetch_data(ip, device_id, endpoint):
    """
    Pobiera dane z danego endpointu dla konkretnego deviceId.
    """
    url = BASE_URL.format(ip=ip) + f"/Devices({device_id}){endpoint}"
    try:
        response = requests.get(url, headers=HEADERS, verify=False)  # verify=False wyłącza weryfikację SSL
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        logging.error(f"Błąd podczas pobierania danych z {url}: {e}")
        return None

def save_to_csv(data, filename, selected_columns=None):
    """
    Zapisuje dane do pliku CSV.
    """
    if not data:
        logging.warning(f"Brak danych do zapisania w {filename}.")
        return

    # Filtruj kolumny, jeśli podano
    if selected_columns:
        filtered_data = []
        for item in data:
            filtered_item = {key: item.get(key, "") for key in selected_columns}
            filtered_data.append(filtered_item)
        data = filtered_data

    # Konwertuj pola dat do formatu epoch, jeśli istnieją
    for item in data:
        for key, value in item.items():
            if isinstance(value, str) and "date" in key.lower():
                epoch_time = parse_date_to_epoch(value)
                if epoch_time:
                    item[key] = epoch_time

    # Zapisz do pliku CSV
    keys = data[0].keys() if isinstance(data, list) and len(data) > 0 else []
    with open(filename, mode='w', newline='') as file:
        writer = csv.DictWriter(file, fieldnames=keys)
        writer.writeheader()
        if isinstance(data, list):
            writer.writerows(data)
        else:
            writer.writerow(data)
    logging.info(f"Dane zapisane do {filename}.")

def process_endpoint(ip, endpoint_name, endpoint_path, devices, output_dir):
    """
    Przetwarza dane dla danego endpointu i zapisuje je do pliku CSV.
    """
    all_data = []
    for device in devices:
        device_id = device["Id"]
        data = fetch_data(ip, device_id, endpoint_path)
        if data:
            # Dodaj DeviceId_IP i SerialNumber do każdego wiersza danych
            for item in data:
                item["DeviceId_IP"] = f"{device_id}_{ip.replace('.', '')}"
                item["DeviceId"] = device_id
                item["SerialNumber"] = device.get("SerialNumber", "")
            all_data.extend(data)

    if all_data:
        # Wybierz odpowiednie kolumny dla określonych endpointów
        selected_columns = ["DeviceId_IP", "DeviceId", "SerialNumber"]
        if endpoint_name == "CPU":
            selected_columns.extend(["CpuName", "Model", "CoreNumber"])
        elif endpoint_name == "InventoryDetails":
            selected_columns.extend(["ModelName", "Name", "DeviceManagement", "Type"])

        # Utwórz nazwę pliku
        ip_without_dots = ip.replace(".", "")
        generation_time = int(datetime.now().timestamp())
        filename = os.path.join(output_dir, f"{ip_without_dots}_{endpoint_name.lower()}_{generation_time}.csv")

        # Zapisz dane do pliku CSV
        save_to_csv(all_data, filename, selected_columns)

def main(ip):
    """
    Główna funkcja skryptu.
    """
    # Utwórz katalog wynikowy
    output_dir = os.path.join(OUTPUT_DIR, ip.replace(".", ""))
    os.makedirs(output_dir, exist_ok=True)
    logging.info(f"Utworzono katalog wynikowy: {output_dir}")

    # Pobierz wszystkie urządzenia z paginacją
    devices = fetch_all_devices(ip)
    if not devices:
        logging.error("Nie udało się pobrać listy urządzeń.")
        return

    # Zapisz dane inwentaryzacyjne do osobnego pliku CSV
    inventory_data = []
    for device in devices:
        inventory_data.append({
            "DeviceId_IP": f"{device['Id']}_{ip.replace('.', '')}",
            "DeviceId": device["Id"],
            "SerialNumber": device.get("SerialNumber", ""),
            "ModelName": device.get("Model", ""),
            "Name": device.get("Name", ""),
            "DeviceManagement": device.get("DeviceManagement", ""),
            "Type": device.get("Type", "")
        })

    # Zapisz dane inwentaryzacyjne
    inventory_filename = os.path.join(output_dir, f"{ip.replace('.', '')}_inventory_{int(datetime.now().timestamp())}.csv")
    save_to_csv(inventory_data, inventory_filename)

    # Endpointy do przetworzenia
    endpoints = {
        "CPU": "/Cpu",
        "Temperature": "/Temperature"
    }

    # Przetwarzaj każdy endpoint
    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures = []
        for endpoint_name, endpoint_path in endpoints.items():
            futures.append(executor.submit(process_endpoint, ip, endpoint_name, endpoint_path, devices, output_dir))
        
        # Czekaj na zakończenie wszystkich wątków
        concurrent.futures.wait(futures)

if __name__ == "__main__":
    if len(sys.argv) != 2:
        logging.error("Użycie: python skrypt.py <IP>")
        sys.exit(1)

    ip = sys.argv[1]
    main(ip)
